import os
import gdown
import joblib
import streamlit as st
import tensorflow as tf
import numpy as np
import pandas as pd
import cv2

# ==============================
# üîπ H√†m x·ª≠ l√Ω trung gian cho CBAM (GI·ªêNG CODE C≈®)
# ==============================
def spatial_mean(t):
    return tf.reduce_mean(t, axis=-1, keepdims=True)

def spatial_max(t):
    return tf.reduce_max(t, axis=-1, keepdims=True)

def spatial_output_shape(s):
    return (s[0], s[1], s[2], 1)

CUSTOM_OBJECTS = {
    "spatial_mean": spatial_mean,
    "spatial_max": spatial_max,
    "spatial_output_shape": spatial_output_shape,
}

# B·∫≠t unsafe_deserialization gi·ªëng code c≈© (n·∫øu Keras cho ph√©p)
try:
    from tensorflow import keras
    keras.config.enable_unsafe_deserialization()
except Exception:
    pass

# ==============================
# üîπ ƒê∆∞·ªùng d·∫´n model & d·ªØ li·ªáu
# ==============================
seg_model_path = "seg_model.keras"
class_model_path = "clf_model.h5"
class_names_path = "class_names.npy"
clinical_model_path = "clinical_epic_gb_model.pkl"
clinical_metadata_path = "clinical_epic_gb_metadata.pkl"
data_path = "Breast_Cancer_METABRIC_Epic_Hospital.csv"

# Google Drive IDs
seg_model_id = "1axOg7N5ssJrMec97eV-JMPzID26ynzN1"
class_model_id = "1fXPICuTkETep2oPiA56l0uMai2GusEJH"
clinical_model_id = "1z1wHVy9xyRXlRqxI8lYXMJhaJaUcKXnu"
clinical_metadata_id = "1WWlfeRqr99VL4nBQ-7eEptIxitKtXj6V"

# ==============================
# üîπ H√†m t·∫£i file t·ª´ Google Drive
# ==============================
def ensure_download(file_id, output_path, description):
    """Download file from Google Drive by ID to the specified output path.
       Returns True if file exists or downloaded successfully, False if failed."""
    if os.path.exists(output_path):
        return True
    try:
        st.info(f"ƒêang t·∫£i {description} t·ª´ Google Drive...")
        # d√πng d·∫°ng id= gi·ªëng code m·ªõi
        gdown.download(id=file_id, output=output_path, quiet=False)
    except Exception as e:
        st.error(f"Kh√¥ng th·ªÉ t·∫£i {description}. Ki·ªÉm tra k·∫øt n·ªëi v√† quy·ªÅn truy c·∫≠p. L·ªói: {e}")
        return False
    if not os.path.exists(output_path):
        st.error(f"T·∫£i {description} th·∫•t b·∫°i, ·ª©ng d·ª•ng s·∫Ω d·ª´ng.")
        return False
    return True

# ==============================
# üîπ T·∫£i c√°c file m√¥ h√¨nh
# ==============================
if not ensure_download(seg_model_id, seg_model_path, "m√¥ h√¨nh ph√¢n ƒëo·∫°n ·∫£nh"):
    st.stop()
if not ensure_download(class_model_id, class_model_path, "m√¥ h√¨nh ph√¢n lo·∫°i ·∫£nh"):
    st.stop()
if not ensure_download(clinical_model_id, clinical_model_path, "m√¥ h√¨nh l√¢m s√†ng"):
    st.stop()
if not ensure_download(clinical_metadata_id, clinical_metadata_path, "si√™u d·ªØ li·ªáu m√¥ h√¨nh l√¢m s√†ng"):
    st.stop()

# ==============================
# üîπ Load m√¥ h√¨nh ·∫£nh (D√ôNG custom_objects GI·ªêNG CODE C≈®)
# ==============================
@st.cache_resource
def load_image_models():
    try:
        seg_model = tf.keras.models.load_model(
            seg_model_path,
            custom_objects=CUSTOM_OBJECTS,
            compile=False,
        )
        class_model = tf.keras.models.load_model(
            class_model_path,
            compile=False,
        )
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i c√°c m√¥ h√¨nh ·∫£nh: {e}")
        st.stop()
    return seg_model, class_model

seg_model, class_model = load_image_models()

# ==============================
# üîπ Load class names
# ==============================
try:
    class_names = np.load(class_names_path)
except Exception:
    class_names = np.array(["B√¨nh th∆∞·ªùng", "L√†nh t√≠nh", "√Åc t√≠nh"])

# ==============================
# üîπ Load m√¥ h√¨nh l√¢m s√†ng & metadata
# ==============================
try:
    clinical_model = joblib.load(clinical_model_path)
    clinical_metadata = joblib.load(clinical_metadata_path)
except Exception as e:
    st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh l√¢m s√†ng: {e}")
    st.stop()

# ==============================
# üîπ Load CSV l√¢m s√†ng
# ==============================
df = None
if os.path.exists(data_path):
    try:
        df = pd.read_csv(data_path)
    except Exception as e:
        st.warning(f"Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu l√¢m s√†ng: {e}")

# ==============================
# üîπ Giao di·ªán ch√≠nh
# ==============================
st.title("H·ªá th·ªëng ch·∫©n ƒëo√°n ung th∆∞ v√∫ th√¥ng minh")
st.write("""
T·∫£i ·∫£nh si√™u √¢m v√∫ ƒë·ªÉ h·ªá th·ªëng x√°c ƒë·ªãnh v·ªã tr√≠ kh·ªëi u v√† ph√¢n lo·∫°i 
kh·ªëi u ƒë√≥ l√† **l√†nh t√≠nh**, **√°c t√≠nh** ho·∫∑c **b√¨nh th∆∞·ªùng**.
""")

# ==============================
# üîπ Ph·∫ßn x·ª≠ l√Ω ·∫£nh
# ==============================
uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh si√™u √¢m (ƒë·ªãnh d·∫°ng JPG/PNG)", type=["jpg", "png"])
if uploaded_file is not None:
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    if image is None:
        st.error("Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh. H√£y th·ª≠ l·∫°i v·ªõi t·ªáp h√¨nh ·∫£nh h·ª£p l·ªá.")
    else:
        orig_image = image.copy()
        orig_height, orig_width = orig_image.shape[0], orig_image.shape[1]

        # ---- Ph√¢n ƒëo·∫°n (U-Net x√°m) ----
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        seg_height, seg_width = seg_model.input_shape[1], seg_model.input_shape[2]
        resized_gray = cv2.resize(gray_image, (seg_width, seg_height))
        input_seg = np.expand_dims(resized_gray, axis=(0, -1))  # (1, H, W, 1)

        pred_mask = seg_model.predict(input_seg)[0]
        mask = (pred_mask.squeeze() >= 0.5).astype(np.uint8)
        mask_full_size = cv2.resize(mask, (orig_width, orig_height), interpolation=cv2.INTER_NEAREST)

        overlay_image = orig_image.copy()
        contours, _ = cv2.findContours(mask_full_size, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(overlay_image, contours, -1, (0, 255, 255), 2)  # v√†ng

        # ---- Ph√¢n lo·∫°i (ResNet / model RGB 224x224) ----
        class_height, class_width = class_model.input_shape[1], class_model.input_shape[2]
        resized_img = cv2.resize(orig_image, (class_width, class_height))
        img_rgb = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)
        img_array = img_rgb.astype(np.float32)
        img_array = img_array / 127.5 - 1.0  # scale -1..1
        img_array = np.expand_dims(img_array, axis=0)

        pred_logits = class_model.predict(img_array)
        pred_probs = tf.nn.softmax(pred_logits[0]).numpy()
        class_idx = int(np.argmax(pred_probs))
        class_label = class_names[class_idx] if class_idx < len(class_names) else str(class_idx)
        confidence = float(np.max(pred_probs))

        col1, col2 = st.columns([1, 1])
        with col1:
            st.subheader("K·∫øt qu·∫£ t·ª´ ·∫£nh si√™u √¢m")
            st.write(f"**Ch·∫©n ƒëo√°n:** {class_label}")
            st.write(f"**X√°c su·∫•t d·ª± ƒëo√°n:** {confidence*100:.2f}%")
        with col2:
            overlay_rgb = cv2.cvtColor(overlay_image, cv2.COLOR_BGR2RGB)
            st.image(overlay_rgb, caption="·∫¢nh si√™u √¢m v·ªõi v√πng kh·ªëi u ƒë∆∞·ª£c ƒë√°nh d·∫•u", use_column_width=True)

# ==============================
# üîπ Ph·∫ßn m√¥ h√¨nh l√¢m s√†ng METABRIC
# ==============================
if df is not None and 'clinical_model' in locals():
    st.markdown("---")
    st.header("D·ª± ƒëo√°n ti√™n l∆∞·ª£ng l√¢m s√†ng (METABRIC)")
    st.write("Ch·ªçn m·ªôt b·ªánh nh√¢n t·ª´ b·ªô d·ªØ li·ªáu METABRIC ƒë·ªÉ d·ª± ƒëo√°n kh·∫£ nƒÉng s·ªëng s√≥t:")

    patient_ids = df["Patient ID"].unique().tolist()
    selected_id = st.selectbox("M√£ b·ªánh nh√¢n:", patient_ids)

    if selected_id:
        patient = df[df["Patient ID"] == selected_id].iloc[0]

        # ---- Chu·∫©n b·ªã ƒë·∫ßu v√†o cho m√¥ h√¨nh l√¢m s√†ng ----
        if isinstance(clinical_metadata, dict) and "features" in clinical_metadata:
            feature_cols = clinical_metadata["features"]
        else:
            cols = [c for c in df.columns if c not in [
                "Patient ID", "Overall Survival (Months)",
                "Overall Survival Status", "Relapse Free Status (Months)",
                "Relapse Free Status", "Patient's Vital Status"
            ]]
            feature_cols = cols

        X_input = patient[feature_cols].copy()

        if isinstance(clinical_metadata, dict):
            # encoders
            if "encoders" in clinical_metadata:
                for col, encoder in clinical_metadata["encoders"].items():
                    if col not in X_input.index:
                        continue
                    try:
                        X_input[col] = encoder.transform([X_input[col]])[0]
                    except Exception:
                        if isinstance(encoder, dict):
                            X_input[col] = encoder.get(X_input[col], X_input[col])

            # scaler
            if "scaler" in clinical_metadata:
                X_df = pd.DataFrame([X_input.values], columns=feature_cols)
                X_scaled = clinical_metadata["scaler"].transform(X_df)
            else:
                X_scaled = np.array([X_input.values])
        else:
            X_scaled = np.array([X_input.values])

        # ---- D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh l√¢m s√†ng ----
        y_pred = clinical_model.predict(X_scaled)
        pred_label = None
        pred_prob = None

        if hasattr(clinical_model, "predict_proba"):
            try:
                prob = clinical_model.predict_proba(X_scaled)
                pred_prob = float(np.max(prob))
            except Exception:
                pred_prob = None

        if isinstance(clinical_metadata, dict) and "target_encoder" in clinical_metadata:
            try:
                pred_label = clinical_metadata["target_encoder"].inverse_transform(y_pred)[0]
            except Exception:
                pred_label = str(y_pred[0])
        elif isinstance(clinical_metadata, dict) and "target_map" in clinical_metadata:
            inv_map = {v: k for k, v in clinical_metadata["target_map"].items()}
            pred_label = inv_map.get(int(y_pred[0]), str(y_pred[0]))
        else:
            pred_label = "Living" if int(y_pred[0]) == 0 else "Died of Disease"

        actual_label = patient["Patient's Vital Status"]

        st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n cho b·ªánh nh√¢n " + selected_id)
        result_text = f"**D·ª± ƒëo√°n c·ªßa m√¥ h√¨nh:** {pred_label}"
        if pred_prob is not None:
            result_text += f" (x√°c su·∫•t {pred_prob*100:.1f}%)"
        st.write(result_text)
        st.write(f"**T√¨nh tr·∫°ng th·ª±c t·∫ø:** {actual_label}")
