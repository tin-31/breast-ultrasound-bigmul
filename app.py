import os
import platform

import gdown
import numpy as np
import pandas as pd
import cv2
import streamlit as st
import altair as alt

import tensorflow as tf
import keras
from keras.models import load_model
from keras.saving import register_keras_serializable
import sklearn

# ============ 0) Keras custom objects cho CBAM/Lambda ============
@register_keras_serializable(package="cbam", name="spatial_mean")
def spatial_mean(x):
    # (B, H, W, C) -> (B, H, W, 1)
    return tf.reduce_mean(x, axis=-1, keepdims=True)

@register_keras_serializable(package="cbam", name="spatial_max")
def spatial_max(x):
    # (B, H, W, C) -> (B, H, W, 1)
    return tf.reduce_max(x, axis=-1, keepdims=True)

@register_keras_serializable(package="cbam", name="spatial_output_shape")
def spatial_output_shape(input_shape):
    """
    Nhi·ªÅu model Keras c≈© l∆∞u output_shape c·ªßa Lambda d∆∞·ªõi d·∫°ng h√†m.
    H√†m n√†y gi√∫p Keras 3 deserialize ƒë∆∞·ª£c.
    """
    try:
        shape = tf.TensorShape(input_shape).as_list()
    except Exception:
        shape = list(input_shape) if isinstance(input_shape, (list, tuple)) else input_shape
    if isinstance(shape, (list, tuple)) and len(shape) >= 3:
        # N·∫øu c√≥ d·∫°ng (..., H, W, C) -> (..., H, W, 1)
        if len(shape) >= 4:
            return (shape[0], shape[1], shape[2], 1)
        # N·∫øu c√≥ d·∫°ng (H, W, C) -> (H, W, 1)
        if len(shape) == 3:
            return (shape[0], shape[1], 1)
    return shape

CUSTOM_OBJECTS = {
    "spatial_mean": spatial_mean,
    "spatial_max": spatial_max,
    "spatial_output_shape": spatial_output_shape,
}

# ============ 1) T·∫£i model t·ª´ Google Drive (1 l·∫ßn) ============
MODEL_DIR = "models"
os.makedirs(MODEL_DIR, exist_ok=True)

# ‚ùó Ch·ªâ gi·ªØ l·∫°i 2 file Keras, b·ªè h·∫≥n c√°c file .pkl
drive_files = {
    "Classifier_model_2.h5": "1fXPICuTkETep2oPiA56l0uMai2GusEJH",
    "best_model_cbam_attention_unet_fixed.keras": "1axOg7N5ssJrMec97eV-JMPzID26ynzN1",
}

with st.spinner("ƒêang ki·ªÉm tra & t·∫£i m√¥ h√¨nh (ch·ªâ l·∫ßn ƒë·∫ßu)‚Ä¶"):
    for fname, fid in drive_files.items():
        dst = os.path.join(MODEL_DIR, fname)
        if not os.path.exists(dst):
            url = f"https://drive.google.com/uc?id={fid}"
            gdown.download(url, dst, quiet=False)

# ============ 2) Load models v·ªõi cache ============
@st.cache_resource
def load_models():
    # Segmentation (Keras 3)
    seg_model = load_model(
        os.path.join(MODEL_DIR, "best_model_cbam_attention_unet_fixed.keras"),
        compile=False,
        custom_objects=CUSTOM_OBJECTS,
        safe_mode=False,   # c·∫ßn False ƒë·ªÉ nh·∫≠n Lambda custom
    )
    # Classifier (h5)
    class_model = load_model(
        os.path.join(MODEL_DIR, "Classifier_model_2.h5"),
        compile=False
    )
    return seg_model, class_model

seg_model, class_model = load_models()

# C√°c model l√¢m s√†ng: KH√îNG d√πng ƒë∆∞·ª£c trong m√¥i tr∆∞·ªùng m·ªõi ‚Üí ƒë·∫∑t None
gb_model = None
gb_meta  = None

# ============ 3) Utils x·ª≠ l√Ω ·∫£nh/overlay ============
def get_input_hwc(model):
    shape = model.input_shape
    if isinstance(shape, list):
        shape = shape[0]
    _, H, W, C = shape
    H = 256 if H is None else int(H)
    W = 256 if W is None else int(W)
    C = 3   if C is None else int(C)
    return H, W, C

def prep_for_model(gray_uint8, target_hwc):
    H, W, C = target_hwc
    resized = cv2.resize(gray_uint8, (W, H), interpolation=cv2.INTER_LINEAR)
    if C == 1:
        x = resized.astype(np.float32) / 255.0
        x = np.expand_dims(x, axis=(0, -1))
    else:
        x = cv2.cvtColor(resized, cv2.COLOR_GRAY2RGB).astype(np.float32) / 255.0
        x = np.expand_dims(x, axis=0)
    return x, resized

# m√†u t√¥: 1= xanh (l√†nh), 2= ƒë·ªè (√°c)
COLOR_BENIGN     = np.array([0, 255, 0], dtype=np.float32)
COLOR_MALIGNANT  = np.array([255, 0, 0], dtype=np.float32)
COLOR_GENERAL    = (0, 255, 255)  # BGR c·ªßa v√†ng khi v·∫Ω contour b·∫±ng OpenCV

def overlay_multiclass_with_general(base_gray_uint8, mask_uint8, alpha=0.6):
    """
    - N·∫øu mask l√† softmax argmax (0..2): 0 n·ªÅn, 1 l√†nh, 2 √°c
    - T√¥ v√πng 1 (xanh), 2 (ƒë·ªè)
    - Vi·ªÅn v√†ng (general lesion) = (mask==1) ‚à™ (mask==2)
    """
    base = np.stack([base_gray_uint8]*3, axis=-1).astype(np.float32)
    over = base.copy()

    m_ben = (mask_uint8 == 1)
    m_mal = (mask_uint8 == 2)

    if np.any(m_ben):
        over[m_ben] = (1 - alpha) * over[m_ben] + alpha * COLOR_BENIGN
    if np.any(m_mal):
        over[m_mal] = (1 - alpha) * over[m_mal] + alpha * COLOR_MALIGNANT

    # Vi·ªÅn v√†ng cho t·ªïng t·ªïn th∆∞∆°ng
    general = (m_ben | m_mal).astype(np.uint8) * 255
    if general.any():
        contours, _ = cv2.findContours(general, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        over_uint8 = np.clip(over, 0, 255).astype(np.uint8)
        cv2.drawContours(over_uint8, contours, -1, COLOR_GENERAL, thickness=2, lineType=cv2.LINE_AA)
        return over_uint8
    return np.clip(over, 0, 255).astype(np.uint8)

# ============ 4) UI ============
st.set_page_config(page_title="Breast Cancer Prediction App", layout="wide")
st.title("Breast Cancer Prediction App")
st.caption(
    "Web cho ph√©p t·∫£i ·∫£nh si√™u √¢m v√∫ ƒë·ªÉ **ph√¢n lo·∫°i & ph√¢n ƒëo·∫°n ƒëa l·ªõp**. "
    "Ph·∫ßn m√¥ h√¨nh l√¢m s√†ng (survival) t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng do file `.pkl` qu√° c≈©."
)

# Hi·ªÉn th·ªã version ƒë·ªÉ debug nhanh
st.sidebar.markdown(
    f"""
**Versions**
- Python: `{platform.python_version()}`
- NumPy: `{np.__version__}`
- scikit-learn: `{sklearn.__version__}`
- TensorFlow: `{tf.__version__}`
- Keras: `{keras.__version__}`
"""
)

tab1, tab2 = st.tabs(["üîé Ultrasound Image Analysis", "üìä Clinical Survival Prediction"])

# ---- Tab 1: ·∫¢nh ----
with tab1:
    st.header("Ultrasound Image Analysis")
    uploaded = st.file_uploader("Choose an ultrasound image (PNG/JPG)", type=["png", "jpg", "jpeg"])

    if uploaded is not None:
        arr = np.frombuffer(uploaded.read(), np.uint8)
        gray = cv2.imdecode(arr, cv2.IMREAD_GRAYSCALE)
        if gray is None:
            st.error("Could not read the image. Please upload a valid image file.")
        else:
            gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

            # Chu·∫©n b·ªã input cho t·ª´ng model
            seg_hwc = get_input_hwc(seg_model)
            clf_hwc = get_input_hwc(class_model)
            x_seg, gray_seg = prep_for_model(gray, seg_hwc)
            x_clf, gray_clf = prep_for_model(gray, clf_hwc)

            # Segmentation (ƒëa l·ªõp)
            with st.spinner("Running segmentation..."):
                seg_pred = seg_model.predict(x_seg, verbose=0)[0]  # (H,W,K) softmax ho·∫∑c (H,W,1)

            if seg_pred.ndim == 3 and seg_pred.shape[-1] >= 3:
                seg_mask = np.argmax(seg_pred, axis=-1).astype(np.uint8)  # 0..K-1
            else:
                # fallback nh·ªã ph√¢n: t√¥ v√†ng t·ªïng t·ªïn th∆∞∆°ng
                seg_mask = (seg_pred[..., 0] >= 0.5).astype(np.uint8) * 1  # 1 = benign gi·∫£
            overlay_img = overlay_multiclass_with_general(gray_seg, seg_mask, alpha=0.6)

            # Classification
            with st.spinner("Running classification..."):
                class_probs = class_model.predict(x_clf, verbose=0)[0]  # (3,)
            class_names = ["benign", "malignant", "normal"]
            vi_map = {"benign": "U l√†nh t√≠nh", "malignant": "U √°c t√≠nh", "normal": "B√¨nh th∆∞·ªùng"}
            pred_idx = int(np.argmax(class_probs))
            pred_label = class_names[pred_idx]

            c1, c2 = st.columns(2)
            with c1:
                st.image(
                    np.stack([gray_clf]*3, axis=-1),
                    caption="Original (resized for classifier)",
                    use_column_width=True,
                )
            with c2:
                st.image(
                    overlay_img,
                    caption="Segmentation overlay (üü© l√†nh / üü• √°c / vi·ªÅn üü® t·ªïng t·ªïn th∆∞∆°ng)",
                    use_column_width=True,
                )

            st.write(
                f"**Classification Result:** {vi_map.get(pred_label, pred_label)} "
                f"(‚âà {float(class_probs[pred_idx]):.2%})"
            )

            probs_df = pd.DataFrame({
                "Category": ["Benign", "Malignant", "Normal"],
                "Probability (%)": (class_probs * 100).round(2)
            })
            st.altair_chart(
                alt.Chart(probs_df).mark_bar().encode(
                    x=alt.X("Category", sort=None),
                    y=alt.Y("Probability (%)", scale=alt.Scale(domain=[0, 100]))
                ),
                use_container_width=True
            )
    else:
        st.info("Please upload a breast ultrasound image to analyze.")

# ---- Tab 2: L√¢m s√†ng ----
with tab2:
    st.header("Clinical Survival Prediction")

    if gb_model is None or gb_meta is None:
        st.warning(
            "Clinical survival model hi·ªán **kh√¥ng kh·∫£ d·ª•ng** trong m√¥i tr∆∞·ªùng n√†y "
            "do file `.pkl` ƒë∆∞·ª£c train v·ªõi NumPy r·∫•t c≈© v√† kh√¥ng th·ªÉ load an to√†n. "
            "Tab n√†y t·∫°m th·ªùi ch·ªâ hi·ªÉn th·ªã th√¥ng b√°o (kh√¥ng c√≥ d·ª± ƒëo√°n)."
        )
    else:
        # N·∫øu sau n√†y b·∫°n c√≥ model m·ªõi (vd: .skops), c√≥ th·ªÉ ƒë·∫∑t code c≈© v√†o ƒë√¢y
        st.info("Clinical model is available. (B·∫°n c√≥ th·ªÉ ch√®n l·∫°i code form + predict ·ªü ƒë√¢y.)")
