# ==========================================
# ðŸ©º á»¨NG Dá»¤NG TRÃ TUá»† NHÃ‚N Táº O Há»– TRá»¢ PHÃ‚N TÃCH áº¢NH SIÃŠU Ã‚M VÃš
# ==========================================
# âš ï¸ PhiÃªn báº£n dÃ nh cho nghiÃªn cá»©u há»c thuáº­t - KhÃ´ng sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch y táº¿ thá»±c táº¿.
# âš ï¸ á»¨ng dá»¥ng nÃ y chá»‰ mang tÃ­nh minh há»a ká»¹ thuáº­t vÃ  há»c thuáº­t.

import os
import json
import tempfile
from pathlib import Path

import numpy as np
import pandas as pd
import cv2
import streamlit as st
import altair as alt

import tensorflow as tf
import keras
from keras.models import load_model
from keras.saving import register_keras_serializable

import joblib
import gdown

# EfficientNetV2 preprocessing
from tensorflow.keras.applications.efficientnet_v2 import preprocess_input as eff_preprocess

# 3D / DICOM
import nibabel as nib
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

# ------------------------------------------------------------
# STREAMLIT CONFIG
# ------------------------------------------------------------
st.set_page_config(
    page_title="AI PhÃ¢n tÃ­ch SiÃªu Ã¢m VÃº",
    layout="wide",
    page_icon="ðŸ©º"
)

# Äáº£m báº£o load model Keras cÅ©
try:
    keras.config.enable_unsafe_deserialization()
except Exception:
    pass

# ------------------------------------------------------------
# CUSTOM OBJECTS DÃ™NG CHO U-NET CBAM
# ------------------------------------------------------------
@register_keras_serializable(package="cbam", name="spatial_mean")
def spatial_mean(x):
    return tf.reduce_mean(x, axis=-1, keepdims=True)

@register_keras_serializable(package="cbam", name="spatial_max")
def spatial_max(x):
    return tf.reduce_max(x, axis=-1, keepdims=True)

@register_keras_serializable(package="cbam", name="spatial_output_shape")
def spatial_output_shape(input_shape):
    shp = tf.TensorShape(input_shape).as_list()
    if len(shp) == 4:
        return (shp[0], shp[1], shp[2], 1)
    if len(shp) == 3:
        return (shp[0], shp[1], 1)
    return shp

CUSTOM_OBJECTS = {
    "spatial_mean": spatial_mean,
    "spatial_max": spatial_max,
    "spatial_output_shape": spatial_output_shape,
}

# ------------------------------------------------------------
# GOOGLE DRIVE MODEL FILES
# ------------------------------------------------------------
MODEL_DIR = "models"

drive_files = {
    "Classifier_model_2.h5": "1fXPICuTkETep2oPiA56l0uMai2GusEJH",
    "best_model_cbam_attention_unet_fixed.keras": "1axOg7N5ssJrMec97eV-JMPzID26ynzN1",
    "clinical_rf_model.joblib": "1zHBB05rVUK7H9eZ9y5N9stUZnhzYBafc",
    "clinical_rf_metadata.json": "1KHZWZXs8QV8jLNXBkAVsQa_DN3tHuXtx",
}

def download_models():
    os.makedirs(MODEL_DIR, exist_ok=True)
    for fname, fid in drive_files.items():
        p = os.path.join(MODEL_DIR, fname)
        if not os.path.exists(p):
            url = f"https://drive.google.com/uc?id={fid}"
            st.info(f"ðŸ“¥ Äang táº£i mÃ´ hÃ¬nh: `{fname}` ...")
            gdown.download(url, p, quiet=False)
            st.success(f"âœ… ÄÃ£ táº£i xong {fname}")

@st.cache_resource
def load_all_models():
    seg = load_model(
        os.path.join(MODEL_DIR, "best_model_cbam_attention_unet_fixed.keras"),
        compile=False,
        custom_objects=CUSTOM_OBJECTS,
        safe_mode=False,
    )

    clf = load_model(
        os.path.join(MODEL_DIR, "Classifier_model_2.h5"),
        compile=False,
    )

    clinical = None
    meta = None
    try:
        clinical = joblib.load(os.path.join(MODEL_DIR, "clinical_rf_model.joblib"))
        with open(os.path.join(MODEL_DIR, "clinical_rf_metadata.json"), "r") as f:
            meta = json.load(f)
    except Exception as e:
        st.error(f"âŒ KhÃ´ng thá»ƒ load mÃ´ hÃ¬nh lÃ¢m sÃ ng: {e}")

    return seg, clf, clinical, meta

# ------------------------------------------------------------
# HÃ€M TIá»€N Xá»¬ LÃ
# ------------------------------------------------------------
def get_input_hwc(model):
    shape = model.input_shape
    if isinstance(shape, list):
        shape = shape[0]
    _, H, W, C = shape
    return int(H), int(W), int(C)

def prep_seg(gray, target_shape):
    """Tiá»n xá»­ lÃ½ cho segmentation U-Net (chuáº©n nhÆ° lÃºc train)."""
    H, W, C = target_shape
    resized = cv2.resize(gray, (W, H))
    if C == 1:
        x = resized.astype(np.float32) / 255.0
        x = np.expand_dims(x, (0, -1))
    else:
        x = cv2.cvtColor(resized, cv2.COLOR_GRAY2RGB).astype(np.float32) / 255.0
        x = np.expand_dims(x, 0)
    return x, resized

def prep_classifier(gray, clf_model):
    """
    Tiá»n xá»­ lÃ½ cho EfficientNetV2B3:
    - Resize vá» (H,W) cá»§a model
    - Chuyá»ƒn grayscale -> RGB
    - DÃ¹ng eff_preprocess (khÃ´ng chia /255)
    """
    _, H, W, C = clf_model.input_shape
    gray_resized = cv2.resize(gray, (W, H))
    rgb = cv2.cvtColor(gray_resized, cv2.COLOR_GRAY2RGB)
    rgb = rgb.astype(np.float32)
    rgb_pp = eff_preprocess(rgb)
    x = np.expand_dims(rgb_pp, axis=0)  # (1,H,W,3)
    return x, gray_resized

# ------------------------------------------------------------
# MÃ€U Váº¼ SEGMENTATION
# ------------------------------------------------------------
COLOR_B = np.array([0, 255, 0], np.float32)   # LÃ nh: xanh lÃ¡
COLOR_M = np.array([255, 0, 0], np.float32)   # Ãc: Ä‘á»
COLOR_G = (0, 255, 255)                       # Viá»n tá»•ng: vÃ ng

def overlay_segmentation(gray, mask, alpha=0.6):
    """Váº½ lá»›p mask (1: lÃ nh, 2: Ã¡c) chá»“ng lÃªn áº£nh xÃ¡m."""
    base = np.stack([gray]*3, axis=-1).astype(np.float32)
    out = base.copy()

    ben = mask == 1
    mal = mask == 2

    if ben.any():
        out[ben] = (1 - alpha) * out[ben] + alpha * COLOR_B
    if mal.any():
        out[mal] = (1 - alpha) * out[mal] + alpha * COLOR_M

    general = ((ben | mal) * 255).astype(np.uint8)
    if general.any():
        ct, _ = cv2.findContours(general, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        out_uint8 = out.clip(0, 255).astype(np.uint8)
        cv2.drawContours(out_uint8, ct, -1, COLOR_G, 2)
        return out_uint8

    return out.clip(0, 255).astype(np.uint8)

# ------------------------------------------------------------
# GRAD-CAM
# ------------------------------------------------------------
def make_gradcam_heatmap(img_array, model, layer_name, class_index=None):
    """
    img_array: (1,H,W,3) Ä‘Ã£ eff_preprocess
    layer_name: tÃªn lá»›p conv cuá»‘i cá»§a EfficientNetV2B3 ("top_conv")
    """
    last_conv = model.get_layer(layer_name)
    grad_model = keras.Model(
        [model.inputs],
        [last_conv.output, model.output],
    )

    with tf.GradientTape() as tape:
        conv_out, preds = grad_model(img_array)
        if isinstance(conv_out, (list, tuple)):
            conv_out = conv_out[0]
        if isinstance(preds, (list, tuple)):
            preds = preds[0]

        if class_index is None:
            class_index = tf.argmax(preds[0])

        class_score = preds[:, class_index]

    grads = tape.gradient(class_score, conv_out)
    pooled = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_out = conv_out[0]
    heat = tf.reduce_mean(conv_out * pooled, axis=-1)
    heat = tf.nn.relu(heat)
    heat = heat / (tf.reduce_max(heat) + 1e-8)
    return heat.numpy()

def mask_heatmap_with_segmentation(heatmap, mask_resized):
    """
    Chá»‰ giá»¯ Grad-CAM trÃªn vÃ¹ng cÃ³ khá»‘i u (mask == 1 hoáº·c 2).
    heatmap: (Hc,Wc) feature map
    mask_resized: (H,W) cÃ¹ng size vá»›i áº£nh classifier
    """
    heatmap = np.squeeze(heatmap)
    H, W = mask_resized.shape[:2]
    heat_resized = cv2.resize(heatmap, (W, H)).astype(np.float32)

    lesion = (mask_resized == 1) | (mask_resized == 2)
    masked = np.zeros_like(heat_resized, dtype=np.float32)
    masked[lesion] = heat_resized[lesion]

    if masked.max() > 0:
        masked /= masked.max()
    return masked

def apply_gradcam_on_gray(gray_resized, heatmap, alpha=0.55, gamma=0.7, thresh=0.15):
    """
    gray_resized: áº£nh xÃ¡m Ä‘Ã£ resize cÃ¹ng size vá»›i classifier
    heatmap: (H,W) 0â€“1 Ä‘Ã£ mask
    """
    H, W = gray_resized.shape[:2]
    heatmap = np.power(heatmap, gamma)
    heatmap[heatmap < thresh] = 0

    heat_uint8 = np.uint8(255 * heatmap)
    heat_color = cv2.applyColorMap(heat_uint8, cv2.COLORMAP_JET)

    base = cv2.cvtColor(gray_resized, cv2.COLOR_GRAY2BGR)
    cam = cv2.addWeighted(heat_color, alpha, base, 1 - alpha, 0)
    return cam

def overlay_contour(cam_img, mask_resized):
    general = ((mask_resized == 1) | (mask_resized == 2)) * 255
    general = general.astype(np.uint8)
    out = cam_img.copy()
    if general.any():
        ct, _ = cv2.findContours(general, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(out, ct, -1, (0, 255, 255), 2)
    return out

# ------------------------------------------------------------
# Äá»ŒC áº¢NH 3D / DICOM
# ------------------------------------------------------------
def load_nifti_slice(file, slice_strategy="middle"):
    img = nib.load(file)
    vol = img.get_fdata()
    mid = vol.shape[2] // 2
    if slice_strategy == "middle":
        slice_img = vol[:, :, mid]
    elif slice_strategy == "max_std":
        idx = np.argmax([np.std(vol[:, :, i]) for i in range(vol.shape[2])])
        slice_img = vol[:, :, idx]
    return slice_img.astype(np.uint8)

def load_dicom_slice(file):
    ds = pydicom.dcmread(file)
    arr = apply_voi_lut(ds.pixel_array, ds)
    arr = arr.astype(np.float32)
    arr = (arr - arr.min()) / (arr.max() - arr.min()) * 255
    return arr.astype(np.uint8)

def load_3d_slice(upload):
    suffix = Path(upload.name).suffix.lower()
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(upload.read())
        tmp_path = tmp.name
    try:
        if suffix in [".nii", ".gz"]:
            return load_nifti_slice(tmp_path), "3D"
        elif suffix == ".dcm":
            return load_dicom_slice(tmp_path), "DICOM"
        else:
            st.error("âŒ Äá»‹nh dáº¡ng áº£nh 3D chÆ°a há»— trá»£ Ä‘á»c.")
            return None, None
    except Exception as e:
        st.error(f"âŒ KhÃ´ng thá»ƒ Ä‘á»c áº£nh: {e}")
        return None, None

# ------------------------------------------------------------
# SIDEBAR
# ------------------------------------------------------------
st.sidebar.title("ðŸ“˜ Danh má»¥c")
chon_trang = st.sidebar.selectbox(
    "Chá»n ná»™i dung hiá»ƒn thá»‹",
    ["á»¨ng dá»¥ng", "Giá»›i thiá»‡u", "Nguá»“n dá»¯ liá»‡u & Báº£n quyá»n"]
)

# ------------------------------------------------------------
# TRANG GIá»šI THIá»†U
# ------------------------------------------------------------
if chon_trang == "Giá»›i thiá»‡u":
    st.title("ðŸ‘©â€âš•ï¸ á»¨NG Dá»¤NG AI Há»– TRá»¢ PHÃ‚N TÃCH áº¢NH SIÃŠU Ã‚M VÃš")
    st.markdown("""
### ðŸŽ¯ Má»¥c tiÃªu

á»¨ng dá»¥ng nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i má»¥c Ä‘Ã­ch **nghiÃªn cá»©u há»c thuáº­t** trong lÄ©nh vá»±c:

- TrÃ­ tuá»‡ nhÃ¢n táº¡o (AI)  
- Há»c sÃ¢u (Deep Learning)  
- Y há»c hÃ¬nh áº£nh (Medical Imaging)  

Cá»¥ thá»ƒ, á»©ng dá»¥ng minh há»a cÃ¡ch:
- PhÃ¢n Ä‘oáº¡n khá»‘i u trÃªn **áº£nh siÃªu Ã¢m tuyáº¿n vÃº** báº±ng máº¡ng U-Net cÃ³ cÆ¡ cháº¿ chÃº Ã½ (CBAM).
- PhÃ¢n loáº¡i khá»‘i u thÃ nh **lÃ nh tÃ­nh / Ã¡c tÃ­nh / bÃ¬nh thÆ°á»ng**.
- Káº¿t há»£p thÃªm mÃ´ hÃ¬nh **dá»¯ liá»‡u lÃ¢m sÃ ng** (RandomForest) Ä‘á»ƒ **há»— trá»£ Ä‘Ã¡nh giÃ¡ nguy cÆ¡**.
- ÄÆ°a ra **nháº­n Ä‘á»‹nh tá»•ng há»£p** tá»« cáº£ hai mÃ´ hÃ¬nh (hÃ¬nh áº£nh + lÃ¢m sÃ ng).

---

### âš ï¸ LÆ°u Ã½ quan trá»ng

- ÄÃ¢y **khÃ´ng pháº£i** lÃ  cÃ´ng cá»¥ cháº©n Ä‘oÃ¡n y khoa thá»±c táº¿.  
- Káº¿t quáº£ tá»« mÃ´ hÃ¬nh chá»‰ mang tÃ­nh **minh há»a ká»¹ thuáº­t** vÃ  **há»— trá»£ há»c thuáº­t**.  

""")

# ------------------------------------------------------------
# TRANG NGUá»’N Dá»® LIá»†U
# ------------------------------------------------------------
elif chon_trang == "Nguá»“n dá»¯ liá»‡u & Báº£n quyá»n":
    st.title("ðŸ“Š Nguá»“n dá»¯ liá»‡u vÃ  báº£n quyá»n sá»­ dá»¥ng")
    st.markdown("""
á»¨ng dá»¥ng sá»­ dá»¥ng dá»¯ liá»‡u tá»« **cÃ¡c nguá»“n cÃ´ng khai** phá»¥c vá»¥ má»¥c Ä‘Ã­ch **nghiÃªn cá»©u phi thÆ°Æ¡ng máº¡i**.
""")

# ------------------------------------------------------------
# TRANG á»¨NG Dá»¤NG
# ------------------------------------------------------------
elif chon_trang == "á»¨ng dá»¥ng":
    st.title("ðŸ©º á»¨NG Dá»¤NG AI MINH Há»ŒA PHÃ‚N TÃCH SIÃŠU Ã‚M VÃš")
    st.markdown("""
á»¨ng dá»¥ng cho phÃ©p:
1. ðŸ“· Táº£i lÃªn **áº£nh siÃªu Ã¢m tuyáº¿n vÃº** Ä‘á»ƒ:
   - PhÃ¢n Ä‘oáº¡n vÃ¹ng nghi ngá».
   - PhÃ¢n loáº¡i: **LÃ nh tÃ­nh / Ãc tÃ­nh / BÃ¬nh thÆ°á»ng**.
2. ðŸ“Š Nháº­p **thÃ´ng tin lÃ¢m sÃ ng** Ä‘á»ƒ mÃ´ hÃ¬nh RandomForest dá»± Ä‘oÃ¡n **káº¿t cá»¥c sá»‘ng cÃ²n**.
3. ðŸ§  Xem **Ä‘Ã¡nh giÃ¡ tá»•ng há»£p**.
""")

    with st.spinner("ðŸ”§ Äang chuáº©n bá»‹ mÃ´ hÃ¬nh..."):
        download_models()
        seg_model, class_model, clinical_model, clinical_meta = load_all_models()

    if clinical_model is None or clinical_meta is None:
        st.error("âŒ KhÃ´ng thá»ƒ táº£i Ä‘áº§y Ä‘á»§ mÃ´ hÃ¬nh lÃ¢m sÃ ng.")

    image_pred_label_en = None
    image_pred_label_vi = None
    image_pred_probs = None
    clinical_pred_label = None
    clinical_prob_death = None

    labels_clf = ["benign", "malignant", "normal"]
    vi_map = {"benign": "U lÃ nh tÃ­nh", "malignant": "U Ã¡c tÃ­nh", "normal": "BÃ¬nh thÆ°á»ng"}

    # --------- áº¢NH ----------
    upload = st.file_uploader(
        "ðŸ“¤ Chá»n áº£nh siÃªu Ã¢m (PNG/JPG hoáº·c NIfTI .nii/.gz hoáº·c DICOM .dcm)",
        ["png", "jpg", "jpeg", "nii", "nii.gz", "dcm"]
    )

    if upload:
        suffix = Path(upload.name).suffix.lower()
        if suffix in [".png", ".jpg", ".jpeg"]:
            arr = np.frombuffer(upload.read(), np.uint8)
            gray = cv2.imdecode(arr, cv2.IMREAD_GRAYSCALE)
            is_3d = False
        elif suffix in [".nii", ".gz", ".dcm"]:
            gray, dim = load_3d_slice(upload)
            is_3d = True
        else:
            st.error("âŒ Äá»‹nh dáº¡ng áº£nh khÃ´ng Ä‘Æ°á»£c há»— trá»£.")
            gray = None
            is_3d = False

        if gray is not None:
            st.info(f"ðŸ“ Há»‡ thá»‘ng phÃ¡t hiá»‡n áº£nh {'3D' if is_3d else '2D'} â€“ Ä‘ang xá»­ lÃ½...")
            gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)

            # Segmentation
            x_seg, g_seg = prep_seg(gray, get_input_hwc(seg_model))
            seg_pred = seg_model.predict(x_seg, verbose=0)[0]
            mask = np.argmax(seg_pred, -1).astype(np.uint8)
            overlay_img = overlay_segmentation(g_seg, mask)

            # Classification (EfficientNetV2B3)
            x_clf, g_clf = prep_classifier(gray, class_model)
            probs = class_model.predict(x_clf, verbose=0)[0]
            idx = int(np.argmax(probs))

            image_pred_label_en = labels_clf[idx]
            image_pred_label_vi = vi_map[image_pred_label_en]
            image_pred_probs = probs

            # Grad-CAM
            gradcam_img = None
            gradcam_with_mask = None
            try:
                last_conv_name = "top_conv"  # EfficientNetV2B3
                class_idx_for_cam = labels_clf.index("malignant")  # hoáº·c idx

                heatmap_raw = make_gradcam_heatmap(
                    img_array=x_clf,
                    model=class_model,
                    layer_name=last_conv_name,
                    class_index=class_idx_for_cam,
                )

                mask_resized = cv2.resize(
                    mask,
                    (g_clf.shape[1], g_clf.shape[0]),
                    interpolation=cv2.INTER_NEAREST,
                )

                heatmap_masked = mask_heatmap_with_segmentation(heatmap_raw, mask_resized)

                gradcam_img = apply_gradcam_on_gray(
                    g_clf,
                    heatmap_masked,
                    alpha=0.55,
                    gamma=0.7,
                    thresh=0.15,
                )

                gradcam_with_mask = overlay_contour(gradcam_img, mask_resized)

            except Exception as e:
                st.warning(f"âš ï¸ KhÃ´ng thá»ƒ táº¡o Grad-CAM: {e}")

            col1, col2, col3 = st.columns(3)
            with col1:
                st.image(g_clf, caption="áº¢nh Ä‘áº§u vÃ o (chuáº©n hÃ³a cho classifier)", use_column_width=True)
            with col2:
                st.image(overlay_img, caption="Káº¿t quáº£ phÃ¢n Ä‘oáº¡n", use_column_width=True)
            with col3:
                if gradcam_with_mask is not None:
                    st.image(
                        gradcam_with_mask,
                        caption="Grad-CAM (lá»›p Ã¡c tÃ­nh) + contour khá»‘i u",
                        use_column_width=True,
                    )
                elif gradcam_img is not None:
                    st.image(
                        gradcam_img,
                        caption="Grad-CAM (lá»›p Ã¡c tÃ­nh)",
                        use_column_width=True,
                    )
                else:
                    st.info("ChÆ°a táº¡o Ä‘Æ°á»£c Grad-CAM cho áº£nh nÃ y.")

            st.success(f"ðŸ” MÃ´ hÃ¬nh hÃ¬nh áº£nh dá»± Ä‘oÃ¡n: **{image_pred_label_vi}** ({probs[idx]*100:.1f}%)")

            df_img = pd.DataFrame({
                "NhÃ³m": ["LÃ nh tÃ­nh", "Ãc tÃ­nh", "BÃ¬nh thÆ°á»ng"],
                "XÃ¡c suáº¥t (%)": (probs * 100).round(2)
            })

            st.altair_chart(
                alt.Chart(df_img).mark_bar().encode(
                    x="NhÃ³m",
                    y="XÃ¡c suáº¥t (%)",
                    tooltip=["NhÃ³m", "XÃ¡c suáº¥t (%)"],
                ),
                use_container_width=True,
            )
    else:
        st.info("ðŸ‘† HÃ£y táº£i lÃªn má»™t áº£nh siÃªu Ã¢m Ä‘á»ƒ mÃ´ hÃ¬nh tiáº¿n hÃ nh minh há»a.")

    # --------- LÃ‚M SÃ€NG ----------
    st.subheader("ðŸ“Š ThÃ´ng tin lÃ¢m sÃ ng (minh há»a)")

    if clinical_model is None or clinical_meta is None:
        st.warning("KhÃ´ng cÃ³ mÃ´ hÃ¬nh lÃ¢m sÃ ng kháº£ dá»¥ng, bá» qua pháº§n nÃ y.")
    else:
        feature_names = clinical_model.feature_names_in_
        label_map = clinical_meta["label_map"]
        inv_label = {v: k for k, v in label_map.items()}

        with st.form("clinical_form"):
            col_a, col_b, col_c = st.columns(3)

            with col_a:
                age = st.number_input("Tuá»•i táº¡i cháº©n Ä‘oÃ¡n (Age at Diagnosis)", 0, 120, 50)
                size = st.number_input("KÃ­ch thÆ°á»›c khá»‘i u (Tumor Size, mm)", 0, 200, 20)
                lymph = st.number_input("Sá»‘ háº¡ch dÆ°Æ¡ng tÃ­nh (Lymph nodes examined positive)", 0, 50, 0)
                mut = st.number_input("Sá»‘ lÆ°á»£ng Ä‘á»™t biáº¿n (Mutation Count)", 0, 10000, 0)
                npi = st.number_input("Chá»‰ sá»‘ Nottingham (NPI)", 0.0, 10.0, 4.0)
                os_m = st.number_input("Thá»i gian sá»‘ng toÃ n bá»™ (Overall Survival, thÃ¡ng)", 0.0, 300.0, 60.0)

            with col_b:
                sx = st.selectbox("Loáº¡i pháº«u thuáº­t vÃº (Type of Breast Surgery)",
                                  ["Breast Conserving", "Mastectomy"])
                grade = st.selectbox("Äá»™ mÃ´ há»c (Neoplasm Histologic Grade)", [1, 2, 3])
                stage = st.selectbox("Giai Ä‘oáº¡n u (Tumor Stage)", [1, 2, 3, 4])
                sex = st.selectbox("Giá»›i tÃ­nh (Sex)", ["Female", "Male"])
                cell = st.selectbox("Cellularity", ["High", "Low", "Moderate"])
                chemo = st.selectbox("HÃ³a trá»‹ (Chemotherapy)", ["No", "Yes"])
                hormone = st.selectbox("Liá»‡u phÃ¡p ná»™i tiáº¿t (Hormone Therapy)", ["No", "Yes"])

            with col_c:
                radio = st.selectbox("Xáº¡ trá»‹ (Radio Therapy)", ["No", "Yes"])
                er = st.selectbox("ER Status", ["Negative", "Positive"])
                pr = st.selectbox("PR Status", ["Negative", "Positive"])
                her2 = st.selectbox("HER2 Status", ["Negative", "Positive"])
                gene = st.selectbox(
                    "3-Gene classifier subtype",
                    [
                        "ER+/HER2+",
                        "ER+/HER2- High Prolif",
                        "ER+/HER2- Low Prolif",
                        "ER-/HER2+",
                        "ER-/HER2-",
                    ],
                )
                pam50 = st.selectbox(
                    "Pam50 + Claudin-low subtype",
                    ["Basal-like", "Claudin-low", "HER2-enriched",
                     "Luminal A", "Luminal B", "Normal-like"],
                )
                relapse = st.selectbox("Tráº¡ng thÃ¡i tÃ¡i phÃ¡t (Relapse Free Status)",
                                       ["Not Recurred", "Recurred"])

                submit_clinical = st.form_submit_button("ðŸ”® Dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh lÃ¢m sÃ ng")

        if submit_clinical:
            row = {
                "Age at Diagnosis": age,
                "Tumor Size": size,
                "Lymph nodes examined positive": lymph,
                "Mutation Count": mut,
                "Nottingham prognostic index": npi,
                "Overall Survival (Months)": os_m,
                "Type of Breast Surgery": sx,
                "Neoplasm Histologic Grade": grade,
                "Tumor Stage": stage,
                "Sex": sex,
                "Cellularity": cell,
                "Chemotherapy": chemo,
                "Hormone Therapy": hormone,
                "Radio Therapy": radio,
                "ER Status": er,
                "PR Status": pr,
                "HER2 Status": her2,
                "3-Gene classifier subtype": gene,
                "Pam50 + Claudin-low subtype": pam50,
                "Relapse Free Status": relapse,
            }

            X = pd.DataFrame([row], columns=feature_names)

            y = int(clinical_model.predict(X)[0])
            pred_label = inv_label[y]
            clinical_pred_label = pred_label

            if "Deceased" in label_map:
                prob_death = float(
                    clinical_model.predict_proba(X)[0][label_map["Deceased"]]
                )
            else:
                prob_death = float(np.max(clinical_model.predict_proba(X)[0]))
            clinical_prob_death = prob_death

            if pred_label == "Deceased":
                st.error(f"ðŸ§¬ MÃ´ hÃ¬nh lÃ¢m sÃ ng dá»± Ä‘oÃ¡n káº¿t cá»¥c: **{pred_label}**")
            else:
                st.success(f"ðŸ§¬ MÃ´ hÃ¬nh lÃ¢m sÃ ng dá»± Ä‘oÃ¡n káº¿t cá»¥c: **{pred_label}**")

            st.write(f"ðŸ“ˆ XÃ¡c suáº¥t tá»­ vong Æ°á»›c tÃ­nh: **{prob_death*100:.1f}%**")

    # --------- ÄÃNH GIÃ Tá»”NG Há»¢P ----------
    st.markdown("---")
    st.subheader("ðŸ§  ÄÃ¡nh giÃ¡ tá»•ng há»£p tá»« hai mÃ´ hÃ¬nh")

    if (image_pred_probs is None) and (clinical_prob_death is None):
        st.info("Khi cÃ³ cáº£ **káº¿t quáº£ mÃ´ hÃ¬nh hÃ¬nh áº£nh** vÃ  **káº¿t quáº£ mÃ´ hÃ¬nh lÃ¢m sÃ ng**, "
                "há»‡ thá»‘ng sáº½ hiá»ƒn thá»‹ Ä‘Ã¡nh giÃ¡ tá»•ng há»£p táº¡i Ä‘Ã¢y.")
    else:
        if image_pred_probs is not None:
            p_malignant = float(image_pred_probs[labels_clf.index("malignant")])
            st.write("ðŸ”¬ **Nháº­n Ä‘á»‹nh tá»« mÃ´ hÃ¬nh hÃ¬nh áº£nh:**")
            st.write(
                f"- Káº¿t luáº­n: **{image_pred_label_vi}** "
                f"(xÃ¡c suáº¥t Ã¡c tÃ­nh â‰ˆ {p_malignant*100:.1f}%)."
            )
        else:
            p_malignant = None

        if clinical_prob_death is not None:
            st.write("ðŸ“‹ **Nháº­n Ä‘á»‹nh tá»« mÃ´ hÃ¬nh lÃ¢m sÃ ng:**")
            st.write(
                f"- Káº¿t cá»¥c dá»± Ä‘oÃ¡n: **{clinical_pred_label}** "
                f"(xÃ¡c suáº¥t tá»­ vong â‰ˆ {clinical_prob_death*100:.1f}%)."
            )
        else:
            clinical_prob_death = None

        if (p_malignant is not None) and (clinical_prob_death is not None):
            combined_risk = 0.6 * p_malignant + 0.4 * clinical_prob_death

            if combined_risk < 0.3:
                risk_group = "Nguy cÆ¡ tháº¥p"
            elif combined_risk < 0.6:
                risk_group = "Nguy cÆ¡ trung bÃ¬nh"
            else:
                risk_group = "Nguy cÆ¡ cao"

            st.write("ðŸ“Ž **Chá»‰ sá»‘ nguy cÆ¡ káº¿t há»£p (minh há»a):**")
            st.write(
                f"- Äiá»ƒm nguy cÆ¡ â‰ˆ **{combined_risk*100:.1f}%** â†’ NhÃ³m: **{risk_group}**."
            )

# ------------------------------------------------------------
# FOOTER
# ------------------------------------------------------------
st.markdown("""
---
ðŸ“˜ **TuyÃªn bá»‘ miá»…n trá»« trÃ¡ch nhiá»‡m:**  
á»¨ng dá»¥ng nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn phá»¥c vá»¥ má»¥c Ä‘Ã­ch **nghiÃªn cá»©u khoa há»c vÃ  giÃ¡o dá»¥c**.  
KhÃ´ng sá»­ dá»¥ng cho **cháº©n Ä‘oÃ¡n, Ä‘iá»u trá»‹ hoáº·c tÆ° váº¥n y táº¿**.  
""")
