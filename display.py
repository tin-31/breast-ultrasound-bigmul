# ==========================================
# ü©∫ ·ª®NG D·ª§NG TR√ç TU·ªÜ NH√ÇN T·∫†O H·ªñ TR·ª¢ PH√ÇN T√çCH ·∫¢NH SI√äU √ÇM V√ö
# ==========================================
# ‚ö†Ô∏è Phi√™n b·∫£n d√†nh cho nghi√™n c·ª©u h·ªçc thu·∫≠t - Kh√¥ng s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch y t·∫ø th·ª±c t·∫ø.
# ‚ö†Ô∏è ·ª®ng d·ª•ng n√†y ch·ªâ mang t√≠nh minh h·ªça k·ªπ thu·∫≠t v√† h·ªçc thu·∫≠t.

import os
import json
import tempfile
from pathlib import Path

import gdown
import numpy as np
import pandas as pd
import cv2
import streamlit as st
import altair as alt

import tensorflow as tf
import keras
from keras.models import load_model
from keras.saving import register_keras_serializable
from keras.layers import Conv2D

import joblib

import nibabel as nib
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

# =====================================================
# ‚öôÔ∏è C·∫§U H√åNH CHUNG
# =====================================================

st.set_page_config(
    page_title="AI Ph√¢n t√≠ch Si√™u √¢m V√∫",
    layout="wide",
    page_icon="ü©∫"
)

# Cho ph√©p load model c≈© (Keras < 3)
try:
    keras.config.enable_unsafe_deserialization()
except Exception:
    pass

# ============================
# 0) CUSTOM OBJECTS CHO CBAM
# ============================
@register_keras_serializable(package="cbam", name="spatial_mean")
def spatial_mean(x):
    return tf.reduce_mean(x, axis=-1, keepdims=True)

@register_keras_serializable(package="cbam", name="spatial_max")
def spatial_max(x):
    return tf.reduce_max(x, axis=-1, keepdims=True)

@register_keras_serializable(package="cbam", name="spatial_output_shape")
def spatial_output_shape(input_shape):
    try:
        shape = tf.TensorShape(input_shape).as_list()
    except Exception:
        shape = list(input_shape)
    if len(shape) == 4:
        return (shape[0], shape[1], shape[2], 1)
    if len(shape) == 3:
        return (shape[0], shape[1], 1)
    return shape

CUSTOM_OBJECTS = {
    "spatial_mean": spatial_mean,
    "spatial_max": spatial_max,
    "spatial_output_shape": spatial_output_shape,
}

# ============================
# 1) T·∫¢I M√î H√åNH T·ª™ GOOGLE DRIVE
# ============================
MODEL_DIR = "models"

drive_files = {
    # M√¥ h√¨nh ph√¢n lo·∫°i + ph√¢n ƒëo·∫°n ·∫£nh si√™u √¢m
    "Classifier_model_2.h5": "1fXPICuTkETep2oPiA56l0uMai2GusEJH",
    "best_model_cbam_attention_unet_fixed.keras": "1axOg7N5ssJrMec97eV-JMPzID26ynzN1",

    # M√¥ h√¨nh l√¢m s√†ng RandomForest + metadata
    "clinical_rf_model.joblib": "1zHBB05rVUK7H9eZ9y5N9stUZnhzYBafc",
    "clinical_rf_metadata.json": "1KHZWZXs8QV8jLNXBkAVsQa_DN3tHuXtx",
}

def download_models():
    os.makedirs(MODEL_DIR, exist_ok=True)
    for fname, fid in drive_files.items():
        path = os.path.join(MODEL_DIR, fname)
        if not os.path.exists(path):
            url = f"https://drive.google.com/uc?id={fid}"
            st.info(f"üì• ƒêang t·∫£i m√¥ h√¨nh: `{fname}` ...")
            gdown.download(url, path, quiet=False)
            st.success(f"‚úÖ ƒê√£ t·∫£i xong {fname}")

# ============================
# 2) LOAD C√ÅC M√î H√åNH
# ============================
@st.cache_resource
def load_all_models():
    """Load m√¥ h√¨nh ph√¢n ƒëo·∫°n, ph√¢n lo·∫°i v√† m√¥ h√¨nh l√¢m s√†ng."""
    seg_model = load_model(
        os.path.join(MODEL_DIR, "best_model_cbam_attention_unet_fixed.keras"),
        compile=False,
        custom_objects=CUSTOM_OBJECTS,
        safe_mode=False
    )

    class_model = load_model(
        os.path.join(MODEL_DIR, "Classifier_model_2.h5"),
        compile=False
    )

    clinical_model = None
    clinical_meta = None
    try:
        clinical_model = joblib.load(os.path.join(MODEL_DIR, "clinical_rf_model.joblib"))
        with open(os.path.join(MODEL_DIR, "clinical_rf_metadata.json"), "r") as f:
            clinical_meta = json.load(f)
    except Exception as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ load m√¥ h√¨nh l√¢m s√†ng: {e}")

    return seg_model, class_model, clinical_model, clinical_meta

# ============================
# 3) H√ÄM X·ª¨ L√ù ·∫¢NH C∆† B·∫¢N
# ============================
def get_input_hwc(model):
    """L·∫•y k√≠ch th∆∞·ªõc (H, W, C) c·ªßa input model Keras."""
    shape = model.input_shape
    if isinstance(shape, list):
        shape = shape[0]
    _, H, W, C = shape
    return int(H), int(W), int(C)

def prep(gray, target_shape):
    """Resize & chu·∫©n h√≥a ·∫£nh x√°m theo k√≠ch th∆∞·ªõc model."""
    H, W, C = target_shape
    resized = cv2.resize(gray, (W, H))
    if C == 1:
        x = resized.astype(np.float32) / 255.0
        x = np.expand_dims(x, (0, -1))
    else:
        x = cv2.cvtColor(resized, cv2.COLOR_GRAY2RGB).astype(np.float32) / 255.0
        x = np.expand_dims(x, 0)
    return x, resized

COLOR_B = np.array([0, 255, 0], np.float32)   # L√†nh: xanh l√°
COLOR_M = np.array([255, 0, 0], np.float32)   # √Åc: ƒë·ªè
COLOR_G = (0, 255, 255)                       # Vi·ªÅn t·ªïng: v√†ng

def overlay(gray, mask, alpha=0.6):
    """V·∫Ω l·ªõp mask (1: l√†nh, 2: √°c) ch·ªìng l√™n ·∫£nh x√°m."""
    base = np.stack([gray]*3, axis=-1).astype(np.float32)
    out = base.copy()

    ben = mask == 1
    mal = mask == 2

    if ben.any():
        out[ben] = (1 - alpha) * out[ben] + alpha * COLOR_B
    if mal.any():
        out[mal] = (1 - alpha) * out[mal] + alpha * COLOR_M

    general = ((ben | mal) * 255).astype(np.uint8)
    if general.any():
        ct, _ = cv2.findContours(general, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        out_uint8 = out.clip(0, 255).astype(np.uint8)
        cv2.drawContours(out_uint8, ct, -1, COLOR_G, 2)
        return out_uint8

    return out.clip(0, 255).astype(np.uint8)

# ============================
# 3.x) H√ÄM GRAD-CAM CHO M√î H√åNH PH√ÇN LO·∫†I
# ============================
def get_last_conv_layer_name(model):
    """
    T√¨m t√™n l·ªõp Conv2D cu·ªëi c√πng trong m√¥ h√¨nh Keras.
    D√πng ƒë·ªÉ l√†m Grad-CAM.
    """
    for layer in reversed(model.layers):
        if isinstance(layer, Conv2D):
            return layer.name
    raise ValueError("Kh√¥ng t√¨m th·∫•y l·ªõp Conv2D n√†o trong m√¥ h√¨nh ƒë·ªÉ l√†m Grad-CAM.")

def make_gradcam_heatmap(img_array,
                         model,
                         last_conv_layer_name,
                         class_index=None):
    """
    img_array: (1, H, W, C) ‚Äì ƒë·∫ßu v√†o ƒë√£ preprocess (ch√≠nh l√† x_clf).
    model: class_model (Classifier_model_2.h5)
    last_conv_layer_name: t√™n l·ªõp conv cu·ªëi (t√¨m b·∫±ng get_last_conv_layer_name)
    class_index: ch·ªâ s·ªë l·ªõp c·∫ßn Grad-CAM (0/1/2).
                 N·∫øu None ‚Üí d√πng l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t.
    """
    last_conv_layer = model.get_layer(last_conv_layer_name)
    grad_model = keras.Model(
        [model.inputs],
        [last_conv_layer.output, model.output],
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)

        # N·∫øu l√† list/tuple th√¨ l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu
        if isinstance(conv_outputs, (list, tuple)):
            conv_outputs = conv_outputs[0]
        if isinstance(predictions, (list, tuple)):
            predictions = predictions[0]

        if class_index is None:
            class_index = tf.argmax(predictions[0])

        class_channel = predictions[:, class_index]

    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_outputs = conv_outputs[0]  # (H, W, C)
    heatmap = tf.reduce_mean(conv_outputs * pooled_grads, axis=-1)  # (H, W)

    heatmap = tf.nn.relu(heatmap)
    heatmap = heatmap / (tf.reduce_max(heatmap) + 1e-8)

    return heatmap.numpy()

def mask_heatmap_with_segmentation(heatmap, mask_resized):
    """
    Ch·ªâ gi·ªØ Grad-CAM tr√™n v√πng c√≥ kh·ªëi u (mask == 1 ho·∫∑c 2).

    heatmap: (Hc, Wc) ‚Äì k√≠ch th∆∞·ªõc feature map (nh·ªè)
    mask_resized: (H, W) ‚Äì c√πng k√≠ch th∆∞·ªõc v·ªõi ·∫£nh classifier (g_clf)
    => H√†m s·∫Ω resize heatmap v·ªÅ (H, W) r·ªìi m·ªõi mask.
    """
    # ƒê·∫£m b·∫£o heatmap l√† 2D
    heatmap = np.squeeze(heatmap)
    if heatmap.ndim == 3:
        # n·∫øu l·ª° l√† (H, W, 1) th√¨ l·∫•y k√™nh ƒë·∫ßu
        heatmap = heatmap[..., 0]

    H, W = mask_resized.shape[:2]

    # Resize heatmap v·ªÅ ƒë√∫ng k√≠ch th∆∞·ªõc mask
    heatmap_resized = cv2.resize(heatmap, (W, H))
    heatmap_resized = heatmap_resized.astype(np.float32)

    # T·∫°o mask v√πng t·ªïn th∆∞∆°ng
    lesion = (mask_resized == 1) | (mask_resized == 2)

    masked = np.zeros_like(heatmap_resized, dtype=np.float32)
    masked[lesion] = heatmap_resized[lesion]

    if masked.max() > 0:
        masked /= masked.max()

    return masked


def apply_gradcam_on_gray(gray, heatmap, alpha=0.6, gamma=0.7, thresh=0.25):
    """
    gray: ·∫£nh x√°m ƒë√£ resize (g_clf)
    heatmap: (H, W) 0‚Äì1 (ƒë√£ mask theo v√πng u)
    alpha: ƒë·ªô ƒë·∫≠m overlay
    gamma: <1 ‚Üí tƒÉng t∆∞∆°ng ph·∫£n v√πng n√≥ng
    thresh: d∆∞·ªõi ng∆∞·ª°ng coi nh∆∞ 0 ƒë·ªÉ n·ªÅn √≠t b·ªã nhu·ªôm m√†u
    """
    h, w = gray.shape[:2]
    heatmap_resized = cv2.resize(heatmap, (w, h))

    heatmap_resized = np.clip(heatmap_resized, 0.0, 1.0).astype(np.float32)

    # TƒÉng t∆∞∆°ng ph·∫£n
    heatmap_gamma = np.power(heatmap_resized, gamma)

    # C·∫Øt ng∆∞·ª°ng
    heatmap_gamma[heatmap_gamma < thresh] = 0.0

    # L√†m m∆∞·ª£t nh·∫π
    heatmap_blur = cv2.GaussianBlur(heatmap_gamma, (5, 5), 0)

    heatmap_uint8 = np.uint8(255 * heatmap_blur)
    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)

    base = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
    cam = cv2.addWeighted(heatmap_color, alpha, base, 1 - alpha, 0)
    return cam

def overlay_mask_contour_on_color(color_img, mask, contour_color=(0, 255, 255), thickness=2):
    """
    color_img: ·∫£nh m√†u (BGR) ‚Äì v√≠ d·ª• Grad-CAM ƒë√£ t√¥ m√†u.
    mask: (H, W), gi√° tr·ªã 0/1/2/... (1: l√†nh, 2: √°c).
    """
    h, w = mask.shape
    general = ((mask == 1) | (mask == 2)) * 255  # v√πng c√≥ u
    general = general.astype(np.uint8)

    out = color_img.copy()
    if general.any():
        ct, _ = cv2.findContours(general, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(out, ct, -1, contour_color, thickness)

    return out

# ============================
# 3.y) H·ªñ TR·ª¢ ƒê·ªåC ·∫¢NH 3D / DICOM
# ============================
def load_nifti_slice(file, slice_strategy="middle"):
    img = nib.load(file)
    vol = img.get_fdata()
    mid = vol.shape[2] // 2
    if slice_strategy == "middle":
        slice_img = vol[:, :, mid]
    elif slice_strategy == "max_std":
        idx = np.argmax([np.std(vol[:, :, i]) for i in range(vol.shape[2])])
        slice_img = vol[:, :, idx]
    return slice_img.astype(np.uint8)

def load_dicom_slice(file):
    ds = pydicom.dcmread(file)
    arr = apply_voi_lut(ds.pixel_array, ds)
    arr = arr.astype(np.float32)
    arr = (arr - arr.min()) / (arr.max() - arr.min()) * 255
    return arr.astype(np.uint8)

def load_3d_slice(upload):
    suffix = Path(upload.name).suffix.lower()
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(upload.read())
        tmp_path = tmp.name
    try:
        if suffix in [".nii", ".gz"]:
            return load_nifti_slice(tmp_path), "3D"
        elif suffix == ".dcm":
            return load_dicom_slice(tmp_path), "DICOM"
        else:
            st.error("‚ùå ƒê·ªãnh d·∫°ng ·∫£nh 3D ch∆∞a h·ªó tr·ª£ ƒë·ªçc.")
            return None, None
    except Exception as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {e}")
        return None, None

# =====================================================
# 4) SIDEBAR & CH·ªåN TRANG
# =====================================================
st.sidebar.title("üìò Danh m·ª•c")
chon_trang = st.sidebar.selectbox(
    "Ch·ªçn n·ªôi dung hi·ªÉn th·ªã",
    ["·ª®ng d·ª•ng", "Gi·ªõi thi·ªáu", "Ngu·ªìn d·ªØ li·ªáu & B·∫£n quy·ªÅn"]
)

# =====================================================
# 5) TRANG 2: GI·ªöI THI·ªÜU
# =====================================================
if chon_trang == "Gi·ªõi thi·ªáu":
    st.title("üë©‚Äç‚öïÔ∏è ·ª®NG D·ª§NG AI H·ªñ TR·ª¢ PH√ÇN T√çCH ·∫¢NH SI√äU √ÇM V√ö")

    st.markdown("""
### üéØ M·ª•c ti√™u

·ª®ng d·ª•ng n√†y ƒë∆∞·ª£c x√¢y d·ª±ng v·ªõi m·ª•c ƒë√≠ch **nghi√™n c·ª©u h·ªçc thu·∫≠t** trong lƒ©nh v·ª±c:

- Tr√≠ tu·ªá nh√¢n t·∫°o (AI)  
- H·ªçc s√¢u (Deep Learning)  
- Y h·ªçc h√¨nh ·∫£nh (Medical Imaging)  

C·ª• th·ªÉ, ·ª©ng d·ª•ng minh h·ªça c√°ch:
- Ph√¢n ƒëo·∫°n kh·ªëi u tr√™n **·∫£nh si√™u √¢m tuy·∫øn v√∫** b·∫±ng m·∫°ng U-Net c√≥ c∆° ch·∫ø ch√∫ √Ω (CBAM).
- Ph√¢n lo·∫°i kh·ªëi u th√†nh **l√†nh t√≠nh / √°c t√≠nh / b√¨nh th∆∞·ªùng**.
- K·∫øt h·ª£p th√™m m√¥ h√¨nh **d·ªØ li·ªáu l√¢m s√†ng** (RandomForest) ƒë·ªÉ **h·ªó tr·ª£ ƒë√°nh gi√° nguy c∆°**.
- ƒê∆∞a ra **nh·∫≠n ƒë·ªãnh t·ªïng h·ª£p** t·ª´ c·∫£ hai m√¥ h√¨nh (h√¨nh ·∫£nh + l√¢m s√†ng).

---

### ‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng

- ƒê√¢y **kh√¥ng ph·∫£i** l√† c√¥ng c·ª• ch·∫©n ƒëo√°n y khoa th·ª±c t·∫ø.  
- K·∫øt qu·∫£ t·ª´ m√¥ h√¨nh ch·ªâ mang t√≠nh **minh h·ªça k·ªπ thu·∫≠t** v√† **h·ªó tr·ª£ h·ªçc thu·∫≠t**.  
- **Tuy·ªát ƒë·ªëi kh√¥ng** s·ª≠ d·ª•ng k·∫øt qu·∫£ t·ª´ ·ª©ng d·ª•ng n√†y ƒë·ªÉ:
  - T·ª± ch·∫©n ƒëo√°n b·ªánh.
  - T·ª± √Ω ƒëi·ªÅu tr·ªã.
  - Thay th·∫ø √Ω ki·∫øn hay ch·ªâ ƒë·ªãnh c·ªßa b√°c sƒ© chuy√™n khoa.

---

### üß™ ƒê·ªëi t∆∞·ª£ng s·ª≠ d·ª•ng

- H·ªçc sinh, sinh vi√™n, nh√† nghi√™n c·ª©u quan t√¢m ƒë·∫øn AI trong y t·∫ø.  
- Ng∆∞·ªùi mu·ªën t√¨m hi·ªÉu quy tr√¨nh: **ti·ªÅn x·ª≠ l√Ω ·∫£nh ‚Üí m√¥ h√¨nh AI ‚Üí di·ªÖn gi·∫£i k·∫øt qu·∫£**.  

---

üìå **T√≥m l·∫°i:**  
·ª®ng d·ª•ng n√†y l√† m·ªôt **m√¥ h√¨nh nghi√™n c·ª©u** (proof-of-concept) v·ªÅ AI trong ch·∫©n ƒëo√°n h√¨nh ·∫£nh, kh√¥ng ph·∫£i s·∫£n ph·∫©m y t·∫ø l√¢m s√†ng.
""")

# =====================================================
# 6) TRANG 3: NGU·ªíN D·ªÆ LI·ªÜU & B·∫¢N QUY·ªÄN
# =====================================================
elif chon_trang == "Ngu·ªìn d·ªØ li·ªáu & B·∫£n quy·ªÅn":
    st.title("üìä Ngu·ªìn d·ªØ li·ªáu v√† b·∫£n quy·ªÅn s·ª≠ d·ª•ng")

    st.markdown("""
·ª®ng d·ª•ng s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ **c√°c ngu·ªìn c√¥ng khai** ph·ª•c v·ª• m·ª•c ƒë√≠ch **nghi√™n c·ª©u phi th∆∞∆°ng m·∫°i**:

| Ngu·ªìn d·ªØ li·ªáu | Lo·∫°i d·ªØ li·ªáu | Li√™n k·∫øt |
|---------------|-------------|---------|
| **BUSI ‚Äì Breast Ultrasound Images Dataset** (Arya Shah, Kaggle) | ·∫¢nh si√™u √¢m tuy·∫øn v√∫ | [M·ªü li√™n k·∫øt](https://www.kaggle.com/datasets/aryashah2k/breast-ultrasound-images-dataset) |
| **BUS-UCLM Breast Ultrasound Dataset** (Orvile, Kaggle) | ·∫¢nh si√™u √¢m tuy·∫øn v√∫ | [M·ªü li√™n k·∫øt](https://www.kaggle.com/datasets/orvile/bus-uclm-breast-ultrasound-dataset) |
| **Breast Lesions USG (TCIA)** | ·∫¢nh si√™u √¢m t·ªïn th∆∞∆°ng v√∫ | [M·ªü li√™n k·∫øt](https://www.cancerimagingarchive.net/collection/breast-lesions-usg/) |
| **Breast Cancer Clinical Data** (Mendeley Data) | D·ªØ li·ªáu l√¢m s√†ng ung th∆∞ v√∫ | [M·ªü li√™n k·∫øt](https://data.mendeley.com/datasets/dbz42w9x8h/2) |

---

### üìÑ Gi·∫•y ph√©p & ph·∫°m vi s·ª≠ d·ª•ng

- D·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng trong ·ª©ng d·ª•ng n√†y **ch·ªâ nh·∫±m m·ª•c ƒë√≠ch nghi√™n c·ª©u khoa h·ªçc v√† gi√°o d·ª•c**.
- Kh√¥ng s·ª≠ d·ª•ng cho:
  - M·ª•c ƒë√≠ch th∆∞∆°ng m·∫°i.
  - C√°c h·ªá th·ªëng ch·∫©n ƒëo√°n y t·∫ø tri·ªÉn khai th·ª±c t·∫ø.
- Khi tr√≠ch d·∫´n ho·∫∑c s·ª≠ d·ª•ng l·∫°i d·ªØ li·ªáu, c·∫ßn tu√¢n th·ªß:
  - ƒêi·ªÅu kho·∫£n gi·∫•y ph√©p ghi r√µ tr√™n t·ª´ng trang dataset.
  - Tr√≠ch d·∫´n t√°c gi·∫£/b·ªô s∆∞u t·∫≠p d·ªØ li·ªáu g·ªëc.

---

### üìö G·ª£i √Ω tr√≠ch d·∫´n (APA, tham kh·∫£o)

- Shah, A. (2020). *Breast Ultrasound Images Dataset* [Dataset]. Kaggle.  
- Orvile. (2023). *BUS-UCLM Breast Ultrasound Dataset* [Dataset]. Kaggle.  
- The Cancer Imaging Archive. (2021). *Breast Lesions USG* [Dataset].  
- Mendeley Data (n.d.). *Breast Cancer Clinical Data* [Dataset]. Mendeley.  

---

üßæ **Tuy√™n b·ªë b·∫£n quy·ªÅn & mi·ªÖn tr·ª´ tr√°ch nhi·ªám:**  
- ·ª®ng d·ª•ng n√†y kh√¥ng s·ªü h·ªØu b·∫£n quy·ªÅn d·ªØ li·ªáu g·ªëc, ch·ªâ s·ª≠ d·ª•ng l·∫°i theo ƒë√∫ng gi·∫•y ph√©p c·ªßa t√°c gi·∫£.  
- T√°c gi·∫£ ·ª©ng d·ª•ng **kh√¥ng ch·ªãu tr√°ch nhi·ªám** cho b·∫•t k·ª≥ vi·ªác s·ª≠ d·ª•ng sai m·ª•c ƒë√≠ch n√†o t·ª´ ph√≠a ng∆∞·ªùi d√πng.
""")

# =====================================================
# 7) TRANG 1: ·ª®NG D·ª§NG CH√çNH (·∫¢NH + L√ÇM S√ÄNG)
# =====================================================
elif chon_trang == "·ª®ng d·ª•ng":
    st.title("ü©∫ ·ª®NG D·ª§NG AI MINH H·ªåA PH√ÇN T√çCH SI√äU √ÇM V√ö")
    st.markdown("""
·ª®ng d·ª•ng cho ph√©p:
1. üì∑ T·∫£i l√™n **·∫£nh si√™u √¢m tuy·∫øn v√∫** ƒë·ªÉ m√¥ h√¨nh:
   - Ph√¢n ƒëo·∫°n v√πng nghi ng·ªù.
   - Ph√¢n lo·∫°i: **L√†nh t√≠nh / √Åc t√≠nh / B√¨nh th∆∞·ªùng**.
2. üìä Nh·∫≠p **th√¥ng tin l√¢m s√†ng c∆° b·∫£n** ƒë·ªÉ m√¥ h√¨nh RandomForest d·ª± ƒëo√°n **k·∫øt c·ª•c s·ªëng c√≤n**.
3. üß† Xem **ƒë√°nh gi√° t·ªïng h·ª£p** ƒë∆∞·ª£c k·∫øt h·ª£p t·ª´ c·∫£ hai m√¥ h√¨nh.

> ‚ö†Ô∏è K·∫øt qu·∫£ ch·ªâ mang t√≠nh **minh h·ªça h·ªçc thu·∫≠t**, kh√¥ng s·ª≠ d·ª•ng cho ch·∫©n ƒëo√°n y khoa th·ª±c t·∫ø.
""")

    # T·∫£i & load m√¥ h√¨nh
    with st.spinner("üîß ƒêang chu·∫©n b·ªã m√¥ h√¨nh..."):
        download_models()
        seg_model, class_model, clinical_model, clinical_meta = load_all_models()

    if clinical_model is None or clinical_meta is None:
        st.error("‚ùå Kh√¥ng th·ªÉ t·∫£i ƒë·∫ßy ƒë·ªß m√¥ h√¨nh l√¢m s√†ng. Vui l√≤ng ki·ªÉm tra l·∫°i file m√¥ h√¨nh.")
    
    # Bi·∫øn l∆∞u k·∫øt qu·∫£ ƒë·ªÉ d√πng cho ph·∫ßn k·∫øt h·ª£p
    image_pred_label_en = None
    image_pred_label_vi = None
    image_pred_probs = None
    clinical_pred_label = None
    clinical_prob_death = None

    labels_clf = ["benign", "malignant", "normal"]
    vi_map = {"benign": "U l√†nh t√≠nh", "malignant": "U √°c t√≠nh", "normal": "B√¨nh th∆∞·ªùng"}

    # ---------------------------------------------
    # 7.1 PH√ÇN T√çCH ·∫¢NH SI√äU √ÇM (2D / 3D / DICOM + GRAD-CAM)
    # ---------------------------------------------
    upload = st.file_uploader(
        "üì§ Ch·ªçn ·∫£nh si√™u √¢m (PNG/JPG ho·∫∑c NIfTI .nii/.gz ho·∫∑c DICOM .dcm)",
        ["png", "jpg", "jpeg", "nii", "nii.gz", "dcm"]
    )

    if upload:
        suffix = Path(upload.name).suffix.lower()
        if suffix in [".png", ".jpg", ".jpeg"]:
            arr = np.frombuffer(upload.read(), np.uint8)
            gray = cv2.imdecode(arr, cv2.IMREAD_GRAYSCALE)
            is_3d = False
        elif suffix in [".nii", ".gz", ".dcm"]:
            gray, dim = load_3d_slice(upload)
            is_3d = True
        else:
            st.error("‚ùå ƒê·ªãnh d·∫°ng ·∫£nh kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£.")
            gray = None
            is_3d = False

        if gray is not None:
            st.info(f"üìÅ H·ªá th·ªëng ph√°t hi·ªán ·∫£nh {'3D' if is_3d else '2D'} ‚Äì ƒëang x·ª≠ l√Ω...")
            gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)

            # Chu·∫©n b·ªã ƒë·∫ßu v√†o cho segmentation v√† classification
            x_seg, g_seg = prep(gray, get_input_hwc(seg_model))
            x_clf, g_clf = prep(gray, get_input_hwc(class_model))

            # D·ª± ƒëo√°n segmentation
            seg_pred = seg_model.predict(x_seg, verbose=0)[0]
            mask = np.argmax(seg_pred, -1).astype(np.uint8)
            overlay_img = overlay(g_seg, mask)

            # D·ª± ƒëo√°n classification
            probs = class_model.predict(x_clf, verbose=0)[0]
            idx = int(np.argmax(probs))

            image_pred_label_en = labels_clf[idx]
            image_pred_label_vi = vi_map[image_pred_label_en]
            image_pred_probs = probs

            # ============================
            # üî• T√çNH GRAD-CAM ƒê·∫∏P H∆†N
            # ============================
            gradcam_img = None
            gradcam_with_mask = None
            try:
                # 1) T√™n l·ªõp Conv2D cu·ªëi
                last_conv_name = get_last_conv_layer_name(class_model)

                # 2) Ch·ªçn l·ªõp c·∫ßn Grad-CAM (√°c t√≠nh)
                class_idx_for_cam = labels_clf.index("malignant")
                # ho·∫∑c: class_idx_for_cam = idx

                # 3) T√≠nh heatmap g·ªëc
                heatmap_raw = make_gradcam_heatmap(
                    img_array=x_clf,
                    model=class_model,
                    last_conv_layer_name=last_conv_name,
                    class_index=class_idx_for_cam,
                )

                # 4) Resize mask v·ªÅ k√≠ch th∆∞·ªõc classifier
                mask_resized = cv2.resize(
                    mask,
                    (g_clf.shape[1], g_clf.shape[0]),
                    interpolation=cv2.INTER_NEAREST,
                )

                # 5) ch·ªâ gi·ªØ Grad-CAM trong v√πng u
                heatmap_masked = mask_heatmap_with_segmentation(heatmap_raw, mask_resized)

                # 6) Overlay Grad-CAM (v√πng n√≥ng trong u)
                gradcam_img = apply_gradcam_on_gray(
                    g_clf,
                    heatmap_masked,
                    alpha=0.6,
                    gamma=0.7,
                    thresh=0.25,
                )

                # 7) Th√™m contour kh·ªëi u cho d·ªÖ nh√¨n
                gradcam_with_mask = overlay_mask_contour_on_color(
                    gradcam_img,
                    mask_resized,
                    contour_color=(0, 255, 255),
                    thickness=2,
                )

            except Exception as e:
                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o Grad-CAM: {e}")

            # Hi·ªÉn th·ªã ·∫£nh
            col1, col2, col3 = st.columns(3)
            with col1:
                st.image(g_clf, caption="·∫¢nh ƒë·∫ßu v√†o (chu·∫©n h√≥a)", use_column_width=True)
            with col2:
                st.image(overlay_img, caption="K·∫øt qu·∫£ ph√¢n ƒëo·∫°n", use_column_width=True)
            with col3:
                if gradcam_with_mask is not None:
                    st.image(
                        gradcam_with_mask,
                        caption="Grad-CAM (l·ªõp √°c t√≠nh) + contour kh·ªëi u",
                        use_column_width=True,
                    )
                elif gradcam_img is not None:
                    st.image(
                        gradcam_img,
                        caption="Grad-CAM (l·ªõp √°c t√≠nh)",
                        use_column_width=True,
                    )
                else:
                    st.info("Ch∆∞a t·∫°o ƒë∆∞·ª£c Grad-CAM cho ·∫£nh n√†y.")

            # Th√¥ng tin ph√¢n lo·∫°i
            st.success(f"üîç M√¥ h√¨nh h√¨nh ·∫£nh d·ª± ƒëo√°n: **{image_pred_label_vi}** ({probs[idx]*100:.1f}%)")

            df_img = pd.DataFrame({
                "Nh√≥m": ["L√†nh t√≠nh", "√Åc t√≠nh", "B√¨nh th∆∞·ªùng"],
                "X√°c su·∫•t (%)": (probs * 100).round(2)
            })

            st.altair_chart(
                alt.Chart(df_img).mark_bar().encode(
                    x="Nh√≥m",
                    y="X√°c su·∫•t (%)",
                    tooltip=["Nh√≥m", "X√°c su·∫•t (%)"],
                ),
                use_container_width=True,
            )
    else:
        st.info("üëÜ H√£y t·∫£i l√™n m·ªôt ·∫£nh si√™u √¢m ƒë·ªÉ m√¥ h√¨nh ti·∫øn h√†nh minh h·ªça.")

        # ---------------------------------------------
        # 7.2 M√î H√åNH L√ÇM S√ÄNG (RANDOMFOREST)
        # ---------------------------------------------
        st.subheader("üìä Th√¥ng tin l√¢m s√†ng (minh h·ªça)")

        if clinical_model is None or clinical_meta is None:
            st.warning("Kh√¥ng c√≥ m√¥ h√¨nh l√¢m s√†ng kh·∫£ d·ª•ng, b·ªè qua ph·∫ßn n√†y.")
        else:
            feature_names = clinical_model.feature_names_in_
            label_map = clinical_meta["label_map"]
            inv_label = {v: k for k, v in label_map.items()}

            with st.form("clinical_form"):
                col_a, col_b, col_c = st.columns(3)

                with col_a:
                    age = st.number_input("Tu·ªïi t·∫°i ch·∫©n ƒëo√°n (Age at Diagnosis)", 0, 120, 50)
                    size = st.number_input("K√≠ch th∆∞·ªõc kh·ªëi u (Tumor Size, mm)", 0, 200, 20)
                    lymph = st.number_input("S·ªë h·∫°ch d∆∞∆°ng t√≠nh (Lymph nodes examined positive)", 0, 50, 0)
                    mut = st.number_input("S·ªë l∆∞·ª£ng ƒë·ªôt bi·∫øn (Mutation Count)", 0, 10000, 0)
                    npi = st.number_input("Ch·ªâ s·ªë Nottingham (NPI)", 0.0, 10.0, 4.0)
                    os_m = st.number_input("Th·ªùi gian s·ªëng to√†n b·ªô (Overall Survival, th√°ng)", 0.0, 300.0, 60.0)

                with col_b:
                    sx = st.selectbox("Lo·∫°i ph·∫´u thu·∫≠t v√∫ (Type of Breast Surgery)",
                                      ["Breast Conserving", "Mastectomy"])
                    grade = st.selectbox("ƒê·ªô m√¥ h·ªçc (Neoplasm Histologic Grade)", [1, 2, 3])
                    stage = st.selectbox("Giai ƒëo·∫°n u (Tumor Stage)", [1, 2, 3, 4])
                    sex = st.selectbox("Gi·ªõi t√≠nh (Sex)", ["Female", "Male"])
                    cell = st.selectbox("Cellularity", ["High", "Low", "Moderate"])
                    chemo = st.selectbox("H√≥a tr·ªã (Chemotherapy)", ["No", "Yes"])
                    hormone = st.selectbox("Li·ªáu ph√°p n·ªôi ti·∫øt (Hormone Therapy)", ["No", "Yes"])

                with col_c:
                    radio = st.selectbox("X·∫° tr·ªã (Radio Therapy)", ["No", "Yes"])
                    er = st.selectbox("ER Status", ["Negative", "Positive"])
                    pr = st.selectbox("PR Status", ["Negative", "Positive"])
                    her2 = st.selectbox("HER2 Status", ["Negative", "Positive"])
                    gene = st.selectbox(
                        "3-Gene classifier subtype",
                        [
                            "ER+/HER2+",
                            "ER+/HER2- High Prolif",
                            "ER+/HER2- Low Prolif",
                            "ER-/HER2+",
                            "ER-/HER2-",
                        ],
                    )
                    pam50 = st.selectbox(
                        "Pam50 + Claudin-low subtype",
                        ["Basal-like", "Claudin-low", "HER2-enriched",
                         "Luminal A", "Luminal B", "Normal-like"],
                    )
                    relapse = st.selectbox("Tr·∫°ng th√°i t√°i ph√°t (Relapse Free Status)",
                                           ["Not Recurred", "Recurred"])

                    submit_clinical = st.form_submit_button("üîÆ D·ª± ƒëo√°n t·ª´ m√¥ h√¨nh l√¢m s√†ng")

            if submit_clinical:
                row = {
                    "Age at Diagnosis": age,
                    "Tumor Size": size,
                    "Lymph nodes examined positive": lymph,
                    "Mutation Count": mut,
                    "Nottingham prognostic index": npi,
                    "Overall Survival (Months)": os_m,
                    "Type of Breast Surgery": sx,
                    "Neoplasm Histologic Grade": grade,
                    "Tumor Stage": stage,
                    "Sex": sex,
                    "Cellularity": cell,
                    "Chemotherapy": chemo,
                    "Hormone Therapy": hormone,
                    "Radio Therapy": radio,
                    "ER Status": er,
                    "PR Status": pr,
                    "HER2 Status": her2,
                    "3-Gene classifier subtype": gene,
                    "Pam50 + Claudin-low subtype": pam50,
                    "Relapse Free Status": relapse,
                }

                X = pd.DataFrame([row], columns=feature_names)

                y = int(clinical_model.predict(X)[0])
                pred_label = inv_label[y]
                clinical_pred_label = pred_label

                if "Deceased" in label_map:
                    prob_death = float(
                        clinical_model.predict_proba(X)[0][label_map["Deceased"]]
                    )
                else:
                    prob_death = float(np.max(clinical_model.predict_proba(X)[0]))
                clinical_prob_death = prob_death

                if pred_label == "Deceased":
                    st.error(f"üß¨ M√¥ h√¨nh l√¢m s√†ng d·ª± ƒëo√°n k·∫øt c·ª•c: **{pred_label}**")
                else:
                    st.success(f"üß¨ M√¥ h√¨nh l√¢m s√†ng d·ª± ƒëo√°n k·∫øt c·ª•c: **{pred_label}**")

                st.write(f"üìà X√°c su·∫•t t·ª≠ vong ∆∞·ªõc t√≠nh: **{prob_death*100:.1f}%**")

        # ---------------------------------------------
        # 7.3 ƒê√ÅNH GI√Å T·ªîNG H·ª¢P (·∫¢NH + L√ÇM S√ÄNG)
        # ---------------------------------------------
        st.markdown("---")
        st.subheader("üß† ƒê√°nh gi√° t·ªïng h·ª£p t·ª´ hai m√¥ h√¨nh")

        if (image_pred_probs is None) and (clinical_prob_death is None):
            st.info("Khi c√≥ c·∫£ **k·∫øt qu·∫£ m√¥ h√¨nh h√¨nh ·∫£nh** v√† **k·∫øt qu·∫£ m√¥ h√¨nh l√¢m s√†ng**, "
                    "h·ªá th·ªëng s·∫Ω hi·ªÉn th·ªã ƒë√°nh gi√° t·ªïng h·ª£p t·∫°i ƒë√¢y.")
        else:
            if image_pred_probs is not None:
                p_malignant = float(image_pred_probs[labels_clf.index("malignant")])
                st.write("üî¨ **Nh·∫≠n ƒë·ªãnh t·ª´ m√¥ h√¨nh h√¨nh ·∫£nh:**")
                st.write(
                    f"- K·∫øt lu·∫≠n: **{image_pred_label_vi}** "
                    f"(x√°c su·∫•t √°c t√≠nh ‚âà {p_malignant*100:.1f}%)."
                )
            else:
                p_malignant = None

            if clinical_prob_death is not None:
                st.write("üìã **Nh·∫≠n ƒë·ªãnh t·ª´ m√¥ h√¨nh l√¢m s√†ng:**")
                st.write(
                    f"- K·∫øt c·ª•c d·ª± ƒëo√°n: **{clinical_pred_label}** "
                    f"(x√°c su·∫•t t·ª≠ vong ‚âà {clinical_prob_death*100:.1f}%)."
                )
            else:
                clinical_prob_death = None

            if (p_malignant is not None) and (clinical_prob_death is not None):
                combined_risk = 0.6 * p_malignant + 0.4 * clinical_prob_death

                if combined_risk < 0.3:
                    risk_group = "Nguy c∆° th·∫•p"
                elif combined_risk < 0.6:
                    risk_group = "Nguy c∆° trung b√¨nh"
                else:
                    risk_group = "Nguy c∆° cao"

                st.write("üìé **Ch·ªâ s·ªë nguy c∆° k·∫øt h·ª£p (minh h·ªça):**")
                st.write(
                    f"- ƒêi·ªÉm nguy c∆° ‚âà **{combined_risk*100:.1f}%** ‚Üí Nh√≥m: **{risk_group}**."
                )

                if risk_group == "Nguy c∆° cao":
                    st.error(
                        "üìå ƒê√°nh gi√° t·ªïng h·ª£p: m√¥ h√¨nh g·ª£i √Ω **nguy c∆° cao**. "
                        "C·∫ßn ƒë∆∞·ª£c b√°c sƒ© chuy√™n khoa thƒÉm kh√°m v√† ƒë√°nh gi√° tr·ª±c ti·∫øp."
                    )
                elif risk_group == "Nguy c∆° trung b√¨nh":
                    st.warning(
                        "üìå ƒê√°nh gi√° t·ªïng h·ª£p: m√¥ h√¨nh g·ª£i √Ω **nguy c∆° trung b√¨nh**. "
                        "C·∫ßn theo d√µi s√°t, k·∫øt h·ª£p th√™m x√©t nghi·ªám v√† ch·∫©n ƒëo√°n h√¨nh ·∫£nh kh√°c."
                    )
                else:
                    st.success(
                        "üìå ƒê√°nh gi√° t·ªïng h·ª£p: m√¥ h√¨nh g·ª£i √Ω **nguy c∆° th·∫•p**. "
                        "Tuy nhi√™n, b·ªánh nh√¢n v·∫´n c·∫ßn t·∫ßm so√°t v√† kh√°m ƒë·ªãnh k·ª≥ theo khuy·∫øn c√°o."
                    )

                st.caption(
                    "‚ö†Ô∏è L∆∞u √Ω: Ch·ªâ s·ªë nguy c∆° k·∫øt h·ª£p tr√™n ch·ªâ l√† **heuristic minh h·ªça**, "
                    "ch∆∞a ƒë∆∞·ª£c hi·ªáu ch·ªânh tr√™n d·ªØ li·ªáu l√¢m s√†ng th·∫≠t. "
                    "Kh√¥ng d√πng ƒë·ªÉ t·ª± ch·∫©n ƒëo√°n ho·∫∑c thay th·∫ø √Ω ki·∫øn b√°c sƒ©."
                )
            else:
                st.info("C·∫ßn c√≥ ƒë·ªß c·∫£ **k·∫øt qu·∫£ h√¨nh ·∫£nh** v√† **k·∫øt qu·∫£ l√¢m s√†ng** "
                        "ƒë·ªÉ t√≠nh to√°n ch·ªâ s·ªë nguy c∆° k·∫øt h·ª£p.")

# =====================================================
# 8) CH√ÇN TRANG (FOOTER)
# =====================================================
st.markdown("""
---
üìò **Tuy√™n b·ªë mi·ªÖn tr·ª´ tr√°ch nhi·ªám:**  
·ª®ng d·ª•ng n√†y ƒë∆∞·ª£c ph√°t tri·ªÉn ph·ª•c v·ª• m·ª•c ƒë√≠ch **nghi√™n c·ª©u khoa h·ªçc v√† gi√°o d·ª•c**.  
Kh√¥ng s·ª≠ d·ª•ng cho **ch·∫©n ƒëo√°n, ƒëi·ªÅu tr·ªã ho·∫∑c t∆∞ v·∫•n y t·∫ø**.  

¬© 2025 ‚Äì D·ª± √°n AI Si√™u √¢m V√∫.  
T√°c gi·∫£ minh h·ªça: L√™ V≈© Anh Tin ‚Äì Tr∆∞·ªùng THPT Chuy√™n Nguy·ªÖn Du.
""")
